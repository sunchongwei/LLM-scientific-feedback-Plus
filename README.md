# LLM-scientific-feedback-Plus
基于GPT3.5/4为论文提供有用的审稿反馈

# 声明
1. 本仓库参考 https://github.com/Weixin-Liang/LLM-scientific-feedback
2. 论文连接 https://arxiv.org/abs/2310.01783
3. 论文的研究内容（摘要）
```
专家反馈奠定了严格研究的基础。 但是，学术生产和复杂知识专业化的快速增长挑战了传统的科学反馈机制。 高质量的同行评审越来越难获得。 少年或资源不足的研究人员特别困难地获得了及时的反馈。 随着大语言模型（LLM）（例如GPT-4）的突破，对使用LLMS来产生有关研究手稿的科学反馈的兴趣越来越大。 但是，LLM生成的反馈的实用性尚未系统地研究。 为了解决这一差距，我们使用GPT-4创建了一条自动管道，以提供有关科学论文的完整PDF的评论。 我们通过两项大规模研究评估了GPT-4的反馈质量。 我们首先将GPT-4的反馈与人类同行评审者的反馈（总共3,096篇论文）和ICLR机器学习会议（1,709篇论文）进行了定量比较。 GPT-4和人类审稿人提出的点的重叠（自然期刊的平均重叠30.85％，ICLR的39.23％）与两个人类审稿人之间的重叠相当（自然界的平均重叠为28.58％，ICLR的平均重叠率为35.25％，ICLR 35.25％，ICLR 35.25％ ）。 对于较弱的论文（即拒绝的ICLR论文；平均重叠43.80％），GPT-4和人类审稿人之间的重叠更大。 然后，我们对来自AI和计算生物学领域的110个美国机构的308位研究人员进行了一项前瞻性用户研究，以了解研究人员如何在他们自己的论文中感知我们的GPT-4系统产生的反馈。 总体而言，超过一半（57.4％）的用户发现GPT-4产生的反馈有用/非常有用，而82.4％的用户发现它比至少一些人类审稿人的反馈更有益。 尽管我们的发现表明LLM生成的反馈可以帮助研究人员，但我们也确定了一些局限性。 例如，GPT-4倾向于专注于科学反馈的某些方面（例如，“在更多数据集中添加实验”），并且经常努力地提供对方法设计的深入批评。 我们的结果在一起表明LLM和人类反馈可以相互补充。 尽管人类专家的审查是并且应该继续是严格的科学过程的基础，但LLM反馈可以使研究人员受益，尤其是在及时的专家反馈不可用的情况下，并且在同行评审前手稿准备的早期阶段。

```
# 为什么会有本仓库
最开始本人是下载的https://github.com/Weixin-Liang/LLM-scientific-feedback仓库的代码，但是在使用的过程中遇到了很多问题，比如在PDF转换成XMl文件的过程中老是出错，还有就是pdf-to-xml服务在部署的过程中也比较容易出错。
为此，我想到了如果通过本地将pdf转化成xml文件，然后再上传给程序给出评审意见。这样一来可以省去部署pdf-to-xml服务的繁琐，二来提升使用过程中的成功率，也是件不错的事情。
另外，项目代码相对简单，仅通过构造合适的prompt然后提交给chatgpt也能达到类似的效果。